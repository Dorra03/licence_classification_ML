================================================================================
PREPROCESSING & FEATURE ENGINEERING REPORT
================================================================================

ðŸ“‹ PIPELINE STEPS
--------------------------------------------------------------------------------
âœ… Step 1: Load cleaned data
âœ… Step 2: Remove redundant columns
âœ… Step 3: Normalize Unicode
âœ… Step 4: Encode categorical variables
âœ… Step 5: Text vectorization (TF-IDF)
âœ… Step 6: Combine features
âœ… Step 7: Train-test split

ðŸ“Š DATA STATISTICS
--------------------------------------------------------------------------------
Total samples: 718
Original columns: 8
Final columns: 6

ðŸ”¤ CATEGORICAL ENCODING
--------------------------------------------------------------------------------

license_type:
  copyleft â†’ 0
  other â†’ 1
  permissive â†’ 2

osi_status:
  not-osi-approved â†’ 0
  osi-approved â†’ 1

ðŸ“ˆ FEATURE ENGINEERING
--------------------------------------------------------------------------------
TF-IDF Configuration:
  max_features: 5000
  ngram_range: (1, 2)
  min_df: 2
  max_df: 0.8
  sublinear_tf: True

Features Summary:
  TF-IDF features: 5000
  Categorical features: 2
  Total features: 5002

ðŸ“Š TRAIN-TEST SPLIT
--------------------------------------------------------------------------------
Train set: 574 samples
Test set: 144 samples
Feature matrix shape:
  X_train: (574, 5002)
  X_test: (144, 5002)
Target variable:
  y_train: 574 samples
  y_test: 144 samples

ðŸŽ¯ TARGET VARIABLE
--------------------------------------------------------------------------------
Total unique classes: 574
Classes in train set: 574
Classes in test set: 144
Most common class: BSD-Protection
Least common class: RPSL-1.0

âœ¨ PREPROCESSING BENEFITS
--------------------------------------------------------------------------------
âœ… Unicode normalization: Consistent text representation
âœ… Redundant column removal: Cleaner feature space
âœ… Categorical encoding: Numbers for ML algorithms
âœ… TF-IDF vectorization: Text â†’ numerical features
âœ… Stratified split: Maintained class distribution

ðŸš€ READY FOR ML MODELS
--------------------------------------------------------------------------------
âœ… Feature matrix: X_train.npz, X_test.npz
âœ… Target labels: y_train.csv, y_test.csv
âœ… Encoders: encoders.pkl
âœ… Vectorizer: vectorizer.pkl

ðŸ“‹ NEXT STEPS
--------------------------------------------------------------------------------
1. Load features: X_train = sparse.load_npz('X_train.npz')
2. Train models: SVM, Random Forest, BERT
3. Evaluate: Accuracy, F1-score, Precision, Recall
4. Compare: ScanCode, FOSSology results